{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для интернет-магазина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Цель - обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Критерий качества модели - значение метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "\n",
    "</span><img src=\"\" align=\"left\" width=\"44,\"></a></span></li></ul></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Анализ\" data-toc-modified-id=\"Анализ-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Анализ</a></span></li><li><span><a href=\"#Предобработка\" data-toc-modified-id=\"Предобработка-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Предобработка</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#CountVectorizer\" data-toc-modified-id=\"CountVectorizer-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>CountVectorizer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Предобработанный-текст-без-лемматизации-и-со-&quot;cтоп-словами&quot;\" data-toc-modified-id=\"Предобработанный-текст-без-лемматизации-и-со-&quot;cтоп-словами&quot;-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Предобработанный текст без лемматизации и со \"cтоп-словами\"</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1.1.1\"><span class=\"toc-item-num\">2.1.1.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.1.1.2\"><span class=\"toc-item-num\">2.1.1.2&nbsp;&nbsp;</span>LightGBM</a></span></li></ul></li><li><span><a href=\"#Текст-после-лемматизации\" data-toc-modified-id=\"Текст-после-лемматизации-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Текст после лемматизации</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1.2.1\"><span class=\"toc-item-num\">2.1.2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.1.2.2\"><span class=\"toc-item-num\">2.1.2.2&nbsp;&nbsp;</span>LightGBM</a></span></li></ul></li></ul></li><li><span><a href=\"#TD-IDF\" data-toc-modified-id=\"TD-IDF-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>TD-IDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#Предобработанный-текст-без-лемматизации-и-со-&quot;cтоп-словами&quot;\" data-toc-modified-id=\"Предобработанный-текст-без-лемматизации-и-со-&quot;cтоп-словами&quot;-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Предобработанный текст без лемматизации и со \"cтоп-словами\"</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.2.1.1\"><span class=\"toc-item-num\">2.2.1.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.2.1.2\"><span class=\"toc-item-num\">2.2.1.2&nbsp;&nbsp;</span>LightGBM</a></span></li></ul></li><li><span><a href=\"#Текст-после-лемматизации\" data-toc-modified-id=\"Текст-после-лемматизации-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Текст после лемматизации</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.2.2.1\"><span class=\"toc-item-num\">2.2.2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.2.2.2\"><span class=\"toc-item-num\">2.2.2.2&nbsp;&nbsp;</span>LightGBM</a></span></li></ul></li></ul></li><li><span><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Word2Vec</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.3.0.1\"><span class=\"toc-item-num\">2.3.0.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.3.0.2\"><span class=\"toc-item-num\">2.3.0.2&nbsp;&nbsp;</span>LightGBM</a></span></li></ul></li></ul></li><li><span><a href=\"#Итоговое-тестирование-модели\" data-toc-modified-id=\"Итоговое-тестирование-модели-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Итоговое тестирование модели</a></span></li><li><span><a href=\"#FastText\" data-toc-modified-id=\"FastText-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>FastText</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li>\n",
    "    \n",
    "<li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка\n",
    "\n",
    "### Анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install wordcloud\n",
    "#!pip install fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, RandomizedSearchCV \n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import gensim.downloader as gensim_api\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('toxic_comments.csv')\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the tools well.  · talk \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contrary to those of DuLithgow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "0                                                                                                                                                                                                                                            Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                     D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                            Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess t...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                  You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                  \"\\n\\nCongratulations from me as well, use the tools well.  · talk \"   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                         COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                  Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.   \n",
       "8                             Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                               alignment on this subject and which are contrary to those of DuLithgow   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      1  \n",
       "7      0  \n",
       "8      0  \n",
       "9      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\\n\\nAsk Sityush to clean up his behavior than issue me nonsensical warnings...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming back! Tosser.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WHite Tiger\\n\\nMeow! Greetingshhh!\\n\\nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\\n\\n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\\n\\n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\\n\\n3 - First a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>I'm Sorry \\n\\nI'm sorry I screwed around with someones talk page.  It was very bad to do.  I know how having the templates on their talk page helps you assert your dominance over them.  I know I should bow down to the almighty administrators.  But then again, I'm going to go play outside....with your mom.   76.122.79.82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>=Tony Sidaway is obviously a fistfuckee. He loves an arm up his ass.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>My Band Page's deletion. You thought I was gone. \\n\\nDeleting the comment I posted on your 'talk page' does not delete my feelings for your hasty decision to delete my page. You, sir, are still a cock-sucking douche fuck. Sit back for a second and think about what your life has become. ............ Done? That didn't take long did it? Nope. Because, as I am most certainly aware, your life is a shitstorm of sitting in front of the computer masturbating to fictional creatures. Your attempts to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text  \\\n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                          COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12                                                                                                                                                                                  Hey... what is it..\\n@ | talk .\\nWhat is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\\n\\nAsk Sityush to clean up his behavior than issue me nonsensical warnings...   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                          Bye! \\n\\nDon't look, come or think of comming back! Tosser.   \n",
       "42  You are gay or antisemmitian? \\n\\nArchangel WHite Tiger\\n\\nMeow! Greetingshhh!\\n\\nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\\n\\n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\\n\\n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\\n\\n3 - First a...   \n",
       "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                             FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "44                                                                                                                                                                                    I'm Sorry \\n\\nI'm sorry I screwed around with someones talk page.  It was very bad to do.  I know how having the templates on their talk page helps you assert your dominance over them.  I know I should bow down to the almighty administrators.  But then again, I'm going to go play outside....with your mom.   76.122.79.82   \n",
       "51                                                                                                                                                                                                                                                                                                                                                                                         GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!   \n",
       "55                                                                                                                                                                                                                                                                                                                                                                                                                            Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!   \n",
       "56                                                                                                                                                                                                                                                                                                                                                                                                                                                 =Tony Sidaway is obviously a fistfuckee. He loves an arm up his ass.   \n",
       "58  My Band Page's deletion. You thought I was gone. \\n\\nDeleting the comment I posted on your 'talk page' does not delete my feelings for your hasty decision to delete my page. You, sir, are still a cock-sucking douche fuck. Sit back for a second and think about what your life has become. ............ Done? That didn't take long did it? Nope. Because, as I am most certainly aware, your life is a shitstorm of sitting in front of the computer masturbating to fictional creatures. Your attempts to ...   \n",
       "\n",
       "    toxic  \n",
       "6       1  \n",
       "12      1  \n",
       "16      1  \n",
       "42      1  \n",
       "43      1  \n",
       "44      1  \n",
       "51      1  \n",
       "55      1  \n",
       "56      1  \n",
       "58      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('toxic==1').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого датасет содержит 159 тыс. комментариев.\n",
    "Всего 10 % из них являются токсичными.\n",
    "\n",
    "### Предобработка\n",
    "\n",
    "Очистим текст от цифр, пунктуации и пробелов.\n",
    "Затем удалим \"стоп-слова\" не несущие особый вклад в смысловую нагрузку текста.\n",
    "\n",
    "Отдельно выделим лемматизированный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Очитска текста\n",
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'[^\\sa-zA-Z0-9@\\[\\]]',' ',text) # Удаляет пунктцацию\n",
    "    text = re.sub(r'\\w*\\d+\\w*', '', text) # Удаляет цифры\n",
    "    text = re.sub('\\s{2,}', \" \", text) # Удаляет ненужные пробелы\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation\\nwhy the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m seemingly stuck with thanks talk january utc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess t...</td>\n",
       "      <td>0</td>\n",
       "      <td>more\\ni can t make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember what page that s on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of asking when your view completely contradicts the coverage in reliable sources why should anyone care what you feel you can t even give a consistent argument is the opening only supposed to mention significant aspects or the most significant ones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that is a horrible thing you put on my talk page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres no actual article for prostitution ring crunch captain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.</td>\n",
       "      <td>0</td>\n",
       "      <td>and it looks like it was actually you who put on the speedy to have the first version deleted now that i look at it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i came here and my idea was bad right away what kind of community goes you have bad ideas go away instead of helping rewrite them</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text  \\\n",
       "0                                                                                                                                                                                                                                                 Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                          D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                 Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess t...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                       You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...   \n",
       "159287                                                                                                                                                                                                            \":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"   \n",
       "159288                                                                                                                                                                                                                                                                                                                                                                                                                You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93   \n",
       "159289                                                                                                                                                                                                                                                                                                                                                                                                                                  Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.   \n",
       "159290                                                                                                                                                                                                                                                                                                                                                                                                 And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.   \n",
       "159291                                                                                                                                                                                                                                                                                                                       \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"   \n",
       "\n",
       "        toxic  \\\n",
       "0           0   \n",
       "1           0   \n",
       "2           0   \n",
       "3           0   \n",
       "4           0   \n",
       "...       ...   \n",
       "159287      0   \n",
       "159288      0   \n",
       "159289      0   \n",
       "159290      0   \n",
       "159291      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 clean_text  \n",
       "0                                                                                                                                                                                                                                                                explanation\\nwhy the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                 d aww he matches this background colour i m seemingly stuck with thanks talk january utc   \n",
       "2                                                                                                                                                                                                                                                                                    hey man i m really not trying to edit war it s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info   \n",
       "3        more\\ni can t make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay...  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                          you sir are my hero any chance you remember what page that s on   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...  \n",
       "159287                                                                                                                                                                                                                                    and for the second time of asking when your view completely contradicts the coverage in reliable sources why should anyone care what you feel you can t even give a consistent argument is the opening only supposed to mention significant aspects or the most significant ones   \n",
       "159288                                                                                                                                                                                                                                                                                                                                                                                                                                  you should be ashamed of yourself that is a horrible thing you put on my talk page   \n",
       "159289                                                                                                                                                                                                                                                                                                                                                                                                                                           spitzer umm theres no actual article for prostitution ring crunch captain   \n",
       "159290                                                                                                                                                                                                                                                                                                                                                                                                 and it looks like it was actually you who put on the speedy to have the first version deleted now that i look at it   \n",
       "159291                                                                                                                                                                                                                                                                                                                                           and i really don t think you understand i came here and my idea was bad right away what kind of community goes you have bad ideas go away instead of helping rewrite them   \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "df['clean_text'] = df['clean_text'].apply(lambda line: tokenizer.tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['most',\n",
       " 'ours',\n",
       " 'have',\n",
       " 'i',\n",
       " \"you'll\",\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'isn',\n",
       " 'same',\n",
       " 'few',\n",
       " \"couldn't\",\n",
       " 'you',\n",
       " 'that',\n",
       " 'am',\n",
       " 'wouldn',\n",
       " 'no',\n",
       " 'about',\n",
       " 'but',\n",
       " 'mustn',\n",
       " \"that'll\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "list(stop_words)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Очитска от стоп-слов\n",
    "df['clean_text_wsw'] = df['clean_text'].apply(lambda words: \n",
    "                    [word for word in words if not word in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Лемматизация\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized'] = df['clean_text_wsw'].apply(lambda c: [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['clean_text', 'clean_text_wsw', 'lemmatized']:\n",
    "    df[col] = df[col].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_wsw</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>explanation why the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now</td>\n",
       "      <td>explanation edits made username hardcore metallica fan reverted vandalisms closure gas voted new york dolls fac please remove template talk page since retired</td>\n",
       "      <td>explanation edits make username hardcore metallica fan revert vandalism closure gas vote new york doll fac please remove template talk page since retire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>d aww he matches this background colour i m seemingly stuck with thanks talk january utc</td>\n",
       "      <td>aww matches background colour seemingly stuck thanks talk january utc</td>\n",
       "      <td>aww match background colour seemingly stuck thanks talk january utc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>hey man i m really not trying to edit war it s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info</td>\n",
       "      <td>hey man really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info</td>\n",
       "      <td>hey man really try edit war guy constantly remove relevant information talk edits instead talk page seem care format actual info</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess t...</td>\n",
       "      <td>more i can t make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay u...</td>\n",
       "      <td>make real suggestions improvement wondered section statistics later subsection types accidents think references may need tidying exact format ie date format etc later one else first preferences formatting style references want please let know appears backlog articles review guess may delay reviewer turns listed relevant form eg wikipedia good article nominations transport</td>\n",
       "      <td>make real suggestion improvement wonder section statistic later subsection type accident think reference may need tidy exact format ie date format etc later one else first preference format style reference want please let know appear backlog article review guess may delay reviewer turn list relevant form eg wikipedia good article nomination transport</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>you sir are my hero any chance you remember what page that s on</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "0                                                                                                                                                                                                                                            Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                     D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                            Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess t...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                  You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            clean_text  \\\n",
       "0                                                                                                                                                                                                                                                             explanation why the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                             d aww he matches this background colour i m seemingly stuck with thanks talk january utc   \n",
       "2                                                                                                                                                                                                                                                                                hey man i m really not trying to edit war it s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info   \n",
       "3  more i can t make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay u...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                      you sir are my hero any chance you remember what page that s on   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                           clean_text_wsw  \\\n",
       "0                                                                                                                                                                                                                          explanation edits made username hardcore metallica fan reverted vandalisms closure gas voted new york dolls fac please remove template talk page since retired   \n",
       "1                                                                                                                                                                                                                                                                                                                   aww matches background colour seemingly stuck thanks talk january utc   \n",
       "2                                                                                                                                                                                                                                           hey man really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info   \n",
       "3  make real suggestions improvement wondered section statistics later subsection types accidents think references may need tidying exact format ie date format etc later one else first preferences formatting style references want please let know appears backlog articles review guess may delay reviewer turns listed relevant form eg wikipedia good article nominations transport   \n",
       "4                                                                                                                                                                                                                                                                                                                                                           sir hero chance remember page   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                         lemmatized  \\\n",
       "0                                                                                                                                                                                                          explanation edits make username hardcore metallica fan revert vandalism closure gas vote new york doll fac please remove template talk page since retire   \n",
       "1                                                                                                                                                                                                                                                                                               aww match background colour seemingly stuck thanks talk january utc   \n",
       "2                                                                                                                                                                                                                                  hey man really try edit war guy constantly remove relevant information talk edits instead talk page seem care format actual info   \n",
       "3  make real suggestion improvement wonder section statistic later subsection type accident think reference may need tidy exact format ie date format etc later one else first preference format style reference want please let know appear backlog article review guess may delay reviewer turn list relevant form eg wikipedia good article nomination transport   \n",
       "4                                                                                                                                                                                                                                                                                                                                     sir hero chance remember page   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['text', 'clean_text', 'clean_text_wsw', 'lemmatized', 'toxic']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "В качестве конвертеров текста будем использовать:\n",
    "* CountVectorizer(на тексте с лемматизацией и без);\n",
    "* TD-IDF(на тексте с лемматизацией и без);\n",
    "* Word2Vec предобученная на твитах (на лемматизированном тексте);\n",
    "\n",
    "Сочетать конвертеры будем с моделями LogisticRegression и LightLBM.\n",
    "\n",
    "Для сравнения также используем модель FastText от Facebook Research.\n",
    "\n",
    "Разделим данные на 2 выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['toxic'], axis=1), df['toxic'], \n",
    "    test_size=0.1, random_state=12345, stratify=df['toxic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report for cross-validation\n",
    "def classification_report_with_f1_score(y_true, y_pred):\n",
    "\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    return f1_score(y_true, y_pred) # return f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_reg = Pipeline(steps=[('count_vect', CountVectorizer(dtype=np.float32)), ('regression', LogisticRegression(C=5.0, solver=\"lbfgs\", n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_clf = Pipeline(steps=[('count_vect', CountVectorizer(dtype=np.float32)), ('classifier', lgb.LGBMClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработанный текст без лемматизации и со \"cтоп-словами\"\n",
    "\n",
    "#####  LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     42932\n",
      "           1       0.84      0.72      0.78      4856\n",
      "\n",
      "    accuracy                           0.96     47788\n",
      "   macro avg       0.91      0.85      0.88     47788\n",
      "weighted avg       0.96      0.96      0.96     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     42932\n",
      "           1       0.83      0.70      0.76      4855\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.90      0.84      0.87     47787\n",
      "weighted avg       0.95      0.96      0.95     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     42931\n",
      "           1       0.83      0.72      0.77      4856\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.90      0.85      0.87     47787\n",
      "weighted avg       0.95      0.96      0.95     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7697977951417293"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                vector_reg , \n",
    "                X_train['clean_text'], y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.92      0.64      0.75      4856\n",
      "\n",
      "    accuracy                           0.96     47788\n",
      "   macro avg       0.94      0.82      0.86     47788\n",
      "weighted avg       0.96      0.96      0.95     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.91      0.62      0.74      4855\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.93      0.81      0.86     47787\n",
      "weighted avg       0.95      0.96      0.95     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42931\n",
      "           1       0.92      0.64      0.76      4856\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.94      0.82      0.87     47787\n",
      "weighted avg       0.96      0.96      0.95     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.748248255219273"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                vector_clf , \n",
    "                X_train['clean_text'], y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Текст после лемматизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     42932\n",
      "           1       0.83      0.72      0.77      4856\n",
      "\n",
      "    accuracy                           0.96     47788\n",
      "   macro avg       0.90      0.85      0.87     47788\n",
      "weighted avg       0.95      0.96      0.95     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     42932\n",
      "           1       0.83      0.70      0.76      4855\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.90      0.84      0.87     47787\n",
      "weighted avg       0.95      0.96      0.95     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     42931\n",
      "           1       0.83      0.71      0.77      4856\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.90      0.85      0.87     47787\n",
      "weighted avg       0.95      0.96      0.95     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7658775263330182"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                vector_reg, \n",
    "                X_train['lemmatized'], y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.89      0.64      0.74      4856\n",
      "\n",
      "    accuracy                           0.95     47788\n",
      "   macro avg       0.92      0.81      0.86     47788\n",
      "weighted avg       0.95      0.95      0.95     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.89      0.63      0.74      4855\n",
      "\n",
      "    accuracy                           0.95     47787\n",
      "   macro avg       0.93      0.81      0.86     47787\n",
      "weighted avg       0.95      0.95      0.95     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42931\n",
      "           1       0.89      0.64      0.74      4856\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.92      0.82      0.86     47787\n",
      "weighted avg       0.95      0.96      0.95     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7403206025767787"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                vector_clf, \n",
    "                X_train['lemmatized'], y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация не улучшает нашу ключевую f1-метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tf_reg = Pipeline(steps=[('tf_vect', TfidfVectorizer(dtype=np.float32)), \n",
    "                                ('regression', LogisticRegression(C=5.0, solver=\"lbfgs\", n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tf_clf = Pipeline(steps=[('tf_vect', TfidfVectorizer(dtype=np.float32)), ('classifier', lgb.LGBMClassifier())]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработанный текст без лемматизации и со \"cтоп-словами\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.91      0.68      0.78      4856\n",
      "\n",
      "    accuracy                           0.96     47788\n",
      "   macro avg       0.94      0.84      0.88     47788\n",
      "weighted avg       0.96      0.96      0.96     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.89      0.67      0.77      4855\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.93      0.83      0.87     47787\n",
      "weighted avg       0.96      0.96      0.96     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42931\n",
      "           1       0.91      0.67      0.77      4856\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.94      0.83      0.87     47787\n",
      "weighted avg       0.96      0.96      0.96     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7720220570703068"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                vector_tf_reg , \n",
    "                X_train['clean_text'], y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.92      0.63      0.75      4856\n",
      "\n",
      "    accuracy                           0.96     47788\n",
      "   macro avg       0.94      0.81      0.86     47788\n",
      "weighted avg       0.96      0.96      0.95     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.91      0.62      0.74      4855\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.94      0.81      0.86     47787\n",
      "weighted avg       0.95      0.96      0.95     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42931\n",
      "           1       0.92      0.64      0.75      4856\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.94      0.82      0.86     47787\n",
      "weighted avg       0.96      0.96      0.95     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7475120325540444"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                vector_tf_clf, \n",
    "                X_train['clean_text'], y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Текст после лемматизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.90      0.68      0.77      4856\n",
      "\n",
      "    accuracy                           0.96     47788\n",
      "   macro avg       0.93      0.84      0.88     47788\n",
      "weighted avg       0.96      0.96      0.96     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.89      0.67      0.76      4855\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.93      0.83      0.87     47787\n",
      "weighted avg       0.96      0.96      0.96     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42931\n",
      "           1       0.90      0.68      0.77      4856\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.93      0.83      0.87     47787\n",
      "weighted avg       0.96      0.96      0.96     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7702310398207728"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                vector_tf_reg, \n",
    "                X_train['lemmatized'], y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.90      0.65      0.76      4856\n",
      "\n",
      "    accuracy                           0.96     47788\n",
      "   macro avg       0.93      0.82      0.87     47788\n",
      "weighted avg       0.96      0.96      0.95     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42932\n",
      "           1       0.90      0.64      0.74      4855\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.93      0.81      0.86     47787\n",
      "weighted avg       0.95      0.96      0.95     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     42931\n",
      "           1       0.90      0.65      0.76      4856\n",
      "\n",
      "    accuracy                           0.96     47787\n",
      "   macro avg       0.93      0.82      0.87     47787\n",
      "weighted avg       0.96      0.96      0.95     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7517438857737363"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                vector_tf_clf, \n",
    "                X_train['lemmatized'], y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество предсказаний на лемматизированном тексте не меняется в сравнии с текстом до лемматизации и исключении стоп-слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# суммирование векторов для модели\n",
    "def vector_sum(text, embeddings):\n",
    "    embeddings_dim = embeddings.vectors.shape[1]\n",
    "    features = np.zeros([embeddings_dim])\n",
    "    for word in text.split():\n",
    "        if word in embeddings:\n",
    "            features += embeddings[word] \n",
    "\n",
    "    return features / len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings_pretrain = gensim_api.load('glove-twitter-200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x23fab7b7910>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vadim\\AppData\\Local\\Temp\\ipykernel_12044\\2757324113.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  return features / len(text.split())\n"
     ]
    }
   ],
   "source": [
    "x_train_wv = np.stack([vector_sum(text, embeddings_pretrain) for text in X_train['lemmatized']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143362, 200)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_wv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_reg = Pipeline(steps=[('imp', SimpleImputer(strategy='constant',fill_value= 0)), \n",
    "                          ('regression', LogisticRegression(C=5.0, solver=\"lbfgs\", n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     42932\n",
      "           1       0.81      0.56      0.67      4856\n",
      "\n",
      "    accuracy                           0.94     47788\n",
      "   macro avg       0.88      0.77      0.82     47788\n",
      "weighted avg       0.94      0.94      0.94     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     42932\n",
      "           1       0.82      0.55      0.66      4855\n",
      "\n",
      "    accuracy                           0.94     47787\n",
      "   macro avg       0.88      0.77      0.81     47787\n",
      "weighted avg       0.94      0.94      0.94     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     42931\n",
      "           1       0.81      0.55      0.66      4856\n",
      "\n",
      "    accuracy                           0.94     47787\n",
      "   macro avg       0.88      0.77      0.81     47787\n",
      "weighted avg       0.94      0.94      0.94     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6605367020846616"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                imp_reg, \n",
    "                x_train_wv, y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_clf = Pipeline(steps=[('imp', SimpleImputer(strategy='constant',fill_value= 0)), \n",
    "                          ('classifier', lgb.LGBMClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     42932\n",
      "           1       0.85      0.60      0.70      4856\n",
      "\n",
      "    accuracy                           0.95     47788\n",
      "   macro avg       0.90      0.79      0.84     47788\n",
      "weighted avg       0.95      0.95      0.94     47788\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     42932\n",
      "           1       0.84      0.58      0.69      4855\n",
      "\n",
      "    accuracy                           0.95     47787\n",
      "   macro avg       0.90      0.78      0.83     47787\n",
      "weighted avg       0.94      0.95      0.94     47787\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     42931\n",
      "           1       0.84      0.59      0.70      4856\n",
      "\n",
      "    accuracy                           0.95     47787\n",
      "   macro avg       0.90      0.79      0.83     47787\n",
      "weighted avg       0.94      0.95      0.94     47787\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6949783603469498"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(\n",
    "                imp_clf, \n",
    "                x_train_wv, y_train, \n",
    "                scoring=make_scorer(classification_report_with_f1_score), \n",
    "                cv = 3\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный предобученный конвертер текста показывает худшее значение метрик в сравнении с предыдущими, более простыми конвертерами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговое тестирование модели\n",
    "\n",
    "Из испытанных моделей в качестве основной выберем логистическую регрессию, в качестве лучшего конвертера определим TD-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf_vect&#x27;, TfidfVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;)),\n",
       "                (&#x27;regression&#x27;, LogisticRegression(C=5.0, n_jobs=-1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf_vect&#x27;, TfidfVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;)),\n",
       "                (&#x27;regression&#x27;, LogisticRegression(C=5.0, n_jobs=-1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=5.0, n_jobs=-1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tf_vect', TfidfVectorizer(dtype=<class 'numpy.float32'>)),\n",
       "                ('regression', LogisticRegression(C=5.0, n_jobs=-1))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_tf_reg.fit(X_train['lemmatized'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     14311\n",
      "           1       0.90      0.70      0.79      1619\n",
      "\n",
      "    accuracy                           0.96     15930\n",
      "   macro avg       0.93      0.85      0.88     15930\n",
      "weighted avg       0.96      0.96      0.96     15930\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = vector_tf_reg.predict(X_test['lemmatized'])\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбранная модель удовлетворяет условию, f1-метрика больше 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__0 thing times moans birkin bardot focus song sound similar female orgasm firstly moans male sound like female orgasm secondly come sound similar female orgasm determine female orgasm sounds heard literaly dozen acoustic versions female orgasms one specific omnipotent one fix shall time\n",
      "__label__0 suicide going take advice shrug unwatching talk\n",
      "__label__0 archive dec\n",
      "__label__0 hello tag added article started simply mentioning individual began dj played raves seem notable article mentioned separated dj dharma years mix sounds employed provided link broken source provided poster user name article name see wikipedia autobiography creating article therefore read like vanity page spam would added tag article showed influenced new york city rave scene years regards\n",
      "__label__0 good morning look satanic comments ip comes orion telekom tim beograd nehruova oriontelekom rs isp dare say rasistic point serbian friends\n",
      "__label__0 comments unfortunately make appear following wp npov wp bio wrote believe mention gay bashing hate crime would lead readers jump unfairly unspoken conclusion mr button gay practically news accounts attacks clear stating attacks intended gay people police court system least one defense attorney attackers said attacks deliberate attempt attack people attackers thought gay nowhere article say mr button gay article says attackers knew nothing mr button sexuality victims attacks targeted random simply area central park attackers believed gay people congregated reason article ignore several news accounts highlight attackers intended attack gay people\n",
      "__label__0 done ive retracted comment seems user admin everyone seems side quite frustrating simply want user leave alone\n",
      "__label__0 ghosh june please add sources adding information sentences sections looking poor someone posted talk page today find information sources talk contributions email\n",
      "__label__0 disagree obama fell key reasons putin vs obama syria one need fresh eyes group stalemate talk\n",
      "__label__0 also asked whether giving assessment talk page response talk\n"
     ]
    }
   ],
   "source": [
    "# Создадим текстовые файля для обучения модели с лейблом и текстом\n",
    "with open('train.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for each_text, each_label in zip(X_train['clean_text_wsw'], y_train):\n",
    "        f.writelines(f'__label__{each_label} {each_text}\\n')\n",
    "        \n",
    "with open('test.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for each_text, each_label in zip(X_test['clean_text_wsw'], y_test):\n",
    "        f.writelines(f'__label__{each_label} {each_text}\\n')\n",
    "\n",
    "# Отобразим, как теперь выглядят наши данные для обучения\n",
    "!head -n 10 train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = fasttext.train_supervised('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_results(sample_size, precision, recall):\n",
    "    precision   = round(precision, 2)\n",
    "    recall      = round(recall, 2)\n",
    "    f1 = round(2*(precision * recall) / (precision + recall), 3)\n",
    "    print(f'{sample_size=}')\n",
    "    print(f'{precision=}')\n",
    "    print(f'{recall=}')\n",
    "    print(f'{f1=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size=15930\n",
      "precision=0.96\n",
      "recall=0.96\n",
      "f1=0.96\n"
     ]
    }
   ],
   "source": [
    "print_results(*model_ft.test('test.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель от Facebook reserch оказалась крайне эффективной в предсказаниях токсичности комментариев.\n",
    "\n",
    "Посмотрим, каким образом она подбирает ближайшие похожие слова, и проверим на паре предложений как определяет токсичность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9998862147331238, 'zivo'),\n",
       " (0.9998844265937805, 'lcv'),\n",
       " (0.9998844265937805, 'abett'),\n",
       " (0.9998840689659119, 'wikidicks'),\n",
       " (0.9998838305473328, 'textbuddy'),\n",
       " (0.9998838305473328, 'ginourmous'),\n",
       " (0.9998832941055298, 'meercat'),\n",
       " (0.9998822212219238, 'ayour'),\n",
       " (0.9998819828033447, 'suckitpedia'),\n",
       " (0.9998819231987, 'mindbogglingly')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.get_nearest_neighbors('ass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9600452780723572, 'ihateyou'),\n",
       " (0.9572011232376099, 'face'),\n",
       " (0.9570577144622803, 'urantia'),\n",
       " (0.9567084908485413, 'abstain'),\n",
       " (0.9559817314147949, 'herad'),\n",
       " (0.9559577703475952, 'sluts'),\n",
       " (0.9558957815170288, 'insensible'),\n",
       " (0.955773651599884, 'bullshits'),\n",
       " (0.9557140469551086, 'truck'),\n",
       " (0.9555983543395996, 'headed')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.get_nearest_neighbors('real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__0',), array([0.98114705]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'how much does potato starch affect a cheese sauce recipe'\n",
    "model_ft.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__1',), array([1.00001001]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'hate you nigger'\n",
    "model_ft.predict(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель хорошо справляется с задачей определения токсичности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были исследованы конвертеры текста в сочетании с моделями градиентного бустинга и логистической регрессии, а также продвинутая модель от Facebook.\n",
    "\n",
    "С поставленной задачей качества предсказаний справились конвертер текста TD-IDF в сочетании с моделью ML LogisticRegression  и модель Fasttext.\n",
    "\n",
    "Самые точные предсказания дает Fasttext."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
